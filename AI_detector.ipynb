{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive"
      ],
      "metadata": {
        "id": "g7V324O2yjZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IUvOuZLvyS9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#設定分割函數"
      ],
      "metadata": {
        "id": "bsl2-jDxkXiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "def split_dataset(source_folder, train_folder, val_folder, split_ratio=0.8):\n",
        "  # 設定隨機種子，確保每次結果一致\n",
        "  random.seed(42)\n",
        "\n",
        "  # 建立目標資料夾\n",
        "  os.makedirs(train_folder, exist_ok=True)\n",
        "  os.makedirs(val_folder, exist_ok=True)\n",
        "\n",
        "  # 取得所有圖片檔案\n",
        "  all_images = [f for f in os.listdir(source_folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "  # 打亂順序\n",
        "  random.shuffle(all_images)\n",
        "\n",
        "  # 計算分割數量\n",
        "  split_index = int(len(all_images) * 0.8)\n",
        "  train_images = all_images[:split_index]\n",
        "  val_images = all_images[split_index:]\n",
        "\n",
        "  # 複製圖片到對應資料夾\n",
        "  for img in train_images:\n",
        "      shutil.copy(os.path.join(source_folder, img), os.path.join(train_folder, img))\n",
        "\n",
        "  for img in val_images:\n",
        "      shutil.copy(os.path.join(source_folder, img), os.path.join(val_folder, img))\n",
        "\n",
        "  print(f\"共處理 {len(all_images)} 張圖片，其中 {len(train_images)} 張放到 train， {len(val_images)} 張放到 val。\")"
      ],
      "metadata": {
        "id": "LNmEGyNripat"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##分割dataset至訓練集和測試集(AI dataset)"
      ],
      "metadata": {
        "id": "PXFhFwYlkeOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s_folder = '/content/drive/MyDrive/dataset/AI'\n",
        "t_folder = '/content/data/train/fake'\n",
        "v_folder = '/content/data/val/fake'\n",
        "split_dataset(source_folder= s_folder,\n",
        "              train_folder= t_folder,\n",
        "              val_folder= v_folder)"
      ],
      "metadata": {
        "id": "ySS8argVj5hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##分割dataset至訓練集和測試集(Real dataset)"
      ],
      "metadata": {
        "id": "Kef5ZAHUkvF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s_folder = '/content/drive/MyDrive/dataset/Real'\n",
        "t_folder = '/content/data/train/real'\n",
        "v_folder = '/content/data/val/real'\n",
        "split_dataset(source_folder= s_folder,\n",
        "              train_folder= t_folder,\n",
        "              val_folder= v_folder)"
      ],
      "metadata": {
        "id": "zAfx1l_8kK_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 清空資料夾(If needed)"
      ],
      "metadata": {
        "id": "nLV2AeLtol5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_folder(folder_path):\n",
        "  # 刪除該資料夾下的所有檔案與子資料夾\n",
        "  for filename in os.listdir(folder_path):\n",
        "      file_path = os.path.join(folder_path, filename)\n",
        "      if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "          os.unlink(file_path)  # 刪除檔案或符號連結\n",
        "      elif os.path.isdir(file_path):\n",
        "          shutil.rmtree(file_path)  # 刪除子資料夾\n",
        "\n",
        "  print(f\"{folder_path} 資料夾內容已清空。\")\n",
        "\n",
        "delete_folder('/content/data/train/fake')\n",
        "delete_folder('/content/data/train/real')\n",
        "delete_folder('/content/data/val/fake')\n",
        "delete_folder('/content/data/val/real')"
      ],
      "metadata": {
        "id": "5emMdgFzoCaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Excution"
      ],
      "metadata": {
        "id": "QqcY89m4kydh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 1. 安裝必要套件（Colab 可用）\n",
        "!pip install torch torchvision matplotlib\n",
        "\n",
        "# 📌 2. 匯入模組\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "\n",
        "# 📌 3. 設定路徑與參數\n",
        "data_dir = \"/content/data\"\n",
        "batch_size = 32\n",
        "num_epochs = 6\n",
        "num_classes = 2  # Real vs AI\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 📌 4. 圖片轉換與資料加載器\n",
        "data_transforms = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    \"val\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "!find /content/data -type d -name \".ipynb_checkpoints\" -exec rm -r {} +\n",
        "print(\"✅ 清除 .ipynb_checkpoints 資料夾成功\")\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)\n",
        "               for x in ['train', 'val']}\n",
        "\n",
        "# 📌 5. 載入 ResNet 模型（ResNet-18）\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# 📌 6. 損失與優化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# 📌 7. 訓練與驗證函式\n",
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n🔁 Epoch {epoch+1}/{num_epochs}\")\n",
        "        for phase in ['train', 'val']:\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            model.train() if phase == 'train' else model.eval()\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "            print(f\"{phase.upper()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "    return model\n",
        "\n",
        "# 📌 8. 開始訓練\n",
        "trained_model = train_model(model, dataloaders, criterion, optimizer, num_epochs)"
      ],
      "metadata": {
        "id": "XeScBoZFXmUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 9. 儲存模型\n",
        "torch.save(trained_model.state_dict(), \"resnet_ai_detector.pth\")\n",
        "shutil.copy(\"resnet_ai_detector.pth\", \"/content/drive/MyDrive/model\")\n",
        "print(\"✅ 模型已儲存\")\n",
        "\n",
        "# 📌 10. 預測單張圖片\n",
        "from PIL import Image\n",
        "\n",
        "def predict_image(image_path, model):\n",
        "    model.eval()\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    transform = data_transforms['val']\n",
        "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        _, pred = torch.max(output, 1)\n",
        "        class_names = image_datasets['train'].classes\n",
        "        print(f\"✅ 預測結果: {class_names[pred.item()]}\")\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Result: {class_names[pred.item()]}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "g-zTW-UxO54M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)  # 和之前保持一致\n",
        "model.load_state_dict(torch.load(\"resnet_ai_detector.pth\", map_location=device))\n",
        "model = model.to(device)\n",
        "\n",
        "predict_image('/content/test/test11.png', model)"
      ],
      "metadata": {
        "id": "QyPOJynKxKNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 錯誤樣本收集"
      ],
      "metadata": {
        "id": "XcXO6ZagX7gQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 設定路徑 ---\n",
        "image_folder = '/content/drive/MyDrive/my_new_dataset/Fake'  # 原始圖片資料夾\n",
        "wrong_folder = '/content/drive/MyDrive/my_new_dataset/wrongly_classified'  # 放錯誤分類圖片\n",
        "\n",
        "# --- 創建錯誤分類資料夾 ---\n",
        "os.makedirs(wrong_folder, exist_ok=True)\n",
        "\n",
        "# --- 圖像預處理要和訓練時一致 ---\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 根據你的模型設計修改\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# --- 載入模型 ---\n",
        "model = models.resnet18(pretrained=False)  # 替換為你的模型類別\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/model/resnet_model.pth'))\n",
        "model.eval().cuda()  # 若有 GPU\n",
        "\n",
        "# --- 推論 ---\n",
        "with torch.no_grad():\n",
        "    for filename in os.listdir(image_folder):\n",
        "        if not filename.lower().endswith(('.jpg', '.png', '.jpeg')): continue\n",
        "\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        input_tensor = transform(image).unsqueeze(0).cuda()\n",
        "\n",
        "        output = model(input_tensor)\n",
        "        pred_class = torch.argmax(output, dim=1).item()\n",
        "\n",
        "        # --- 這裡依照檔名判斷真實標籤 ---\n",
        "        if filename.lower().startswith(\"real\"):\n",
        "            label = 0\n",
        "        elif filename.lower().startswith(\"fake\"):\n",
        "            label = 1\n",
        "        else:\n",
        "            print(f\"無法判斷標籤: {filename}\")\n",
        "            continue\n",
        "\n",
        "        # --- 判斷錯誤就複製圖片過去 ---\n",
        "        if pred_class != label:\n",
        "            shutil.copy(image_path, os.path.join(wrong_folder, filename))\n",
        "            print(f\"[錯誤分類] 已移動: {filename}\")\n"
      ],
      "metadata": {
        "id": "SWkVFLxxUwgS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}